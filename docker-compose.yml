services:
  prediction_app:
    build:
      context: .
      dockerfile: prediction_app/Dockerfile
    environment:
      PORT: "5703"
      # Optional (only required if you want AI explanations/insights).
      VOLCENGINE_API_KEY2: ${VOLCENGINE_API_KEY2:-a0533576-d6ed-4ca4-a308-473cbf7ebd10}
      VOLCENGINE_BASE_URL: ${VOLCENGINE_BASE_URL:-https://ark.cn-beijing.volces.com/api/v3}
      VOLCENGINE_MODEL: ${VOLCENGINE_MODEL:-kimi-k2-250905}
    volumes:
      - ./uploads:/app/uploads
    ports:
      # Exposed for debugging; the UI talks to the agent which reverse-proxies to this service.
      - "5703:5703"
    restart: unless-stopped

  agent:
    build:
      context: ./agent
      dockerfile: Dockerfile
    environment:
      PORT: "5702"
      PYTHON_API_URL: http://prediction_app:5703
      UPLOAD_DIR: /app/uploads
      # Optional (LLM provider for the agent + some Python insight endpoints).
      VOLCENGINE_API_KEY2: ${VOLCENGINE_API_KEY2:-}
      VOLCENGINE_API_URL: ${VOLCENGINE_API_URL:-https://ark.cn-beijing.volces.com/api/v3}
      VOLCENGINE_MODEL: ${VOLCENGINE_MODEL:-kimi-k2-250905}
      # Optional (RTC Voice Chat)
      VOLCENGINE_APP_ID: ${VOLCENGINE_APP_ID:-}
      VOLCENGINE_APP_KEY: ${VOLCENGINE_APP_KEY:-}
      VOLC_ACCESSKEY: ${VOLC_ACCESSKEY:-}
      VOLC_SECRETKEY: ${VOLC_SECRETKEY:-}
      VOLC_REGION: ${VOLC_REGION:-cn-north-1}
      VOLC_RTC_API_URL: ${VOLC_RTC_API_URL:-https://rtc.volcengineapi.com}
      VOLC_SPEECH_APP_ID: ${VOLC_SPEECH_APP_ID:-}
      COZEBOT_APIKEY: ${COZEBOT_APIKEY:-}
      COZEBOT_BOT_ID: ${COZEBOT_BOT_ID:-}
      COZEBOT_URL: ${COZEBOT_URL:-https://api.coze.cn}
    volumes:
      - ./uploads:/app/uploads
      - ./lattice_store:/app/lattice_store
    depends_on:
      - prediction_app
    ports:
      - "5702:5702"
    restart: unless-stopped

  ai_web:
    build:
      context: ./ai_web
      dockerfile: Dockerfile
    depends_on:
      - agent
    ports:
      - "5701:5701"
    restart: unless-stopped
